# This is the master config. It is most likely not runnable but lists all 
# available options

# All IPs and ports given in here are the defaults for a lab setup.

# Mandatory options are given, optional options are commented out
# and listed with the default values 

# This defines the pose service to use.
# Requirements: None
[PoseService]
ip = "192.168.0.8"
port = 53249        # default value is hexadecimal 0xd001

# This defines the specifics for the robot
# Requirements: PoseService
[Robot]
# The size of the "bubble" in which no modifications or deletions of objects
# are sent to the robot. **In meters**
# This is required because the camera angle prevents the robot from seeing
# the environment directly below its feet  
bubble_size = 1.2

# Video source 
[VideoSource]
# Common options:
#   - `type`: stream, oni, pcd, am_offline
# `oni` and `pcd` types require an additional parameter: file_path
# `am_offline` type requires an additional parameters: dir_path
type = "stream"
#file_path = "path/to/file"
#dir_path = "path/to/folder"
#enable_rgb = false  # Capture RGB images
#enable_pose = false  # Replay pose data (only am_offline)

# This sets up the filtered source, which will be passed to all
# steps requiring a video 
[FilteredVideoSource]
# TODO: describe options
# options: "simple", "prob", "pt1"
type = "simple"

  # The following list of filters is optional
  # The order of the filters themselves IS NOT SIGNIFICANT.
  # each filter requires a "type" and may need additional options

  [[FilteredVideoSource.filters]]
  # Calibration filters. Sets the calibration parameters of the used camera
  type = "SensorCalibrationFilter"
  a = 1.0117
  b = -0.0100851

  [[FilteredVideoSource.filters]]
  # The RobotOdoTransformer transforms coordinates from the local coordinate
  # sytem to the global one referenced in Lola's right foot sole
  # Requirements: PoseService
  type = "RobotOdoTransformer"

  [[FilteredVideoSource.filters]]
  # TODO: What's that?
  type = "FileOdoTransformer"
  file_path = "some/path"
  
  [[FilteredVideoSource.filters]]
  # This filter truncates all values to the specified amount of digits
  # after the dot.
  type = "TruncateFilter"
  # Base unit is meters, so 2 truncates to millimeters
  decimal_points = 2

  [[FilteredVideoSource.filters]]
  # The crop filter erases all points out of the given boundaries.
  # This is used to ignore everything outside of the experimental area 
  type = "CropFilter"
  # Unit in meters
  xmax = 4
  xmin = -1.5
  ymax = 1.5
  ymin = -1.5

###########################################################################
# Observers is an array
# this will list all observers and options belonging to them

# This observer saves the input data. The saved data can be replayed later
# with the "am_offline" video source
[[observers]]
type = "Recorder"

  [ObserverOptions.Recorder]
  # Output directory. The final output will end up in a subfolder named
  # "rec_{datetime}" 
  output_folder= "recordings"
  # Defines which data to record
  #cloud = true
  #rgb = false
  #pose = false

# This helps to calibrate the camera
# It requires a corresponding visualizer  
[[observers]]
type = "CameraCalibrator"

# This defines all available visualizers, there can be more than one
[[observers]]
type = "ARVisualizer"

# Every instance has 4 mandatory options:
# - type: the type of the visualizer
# - name: its name
# - width
# and 
# - height: the window dimensions

  # This visualizer belongs to the CameraCalibrator. It shows the calibartion parameters
  [[observers.visualizer]]
  type = "CameraCalibrator"
  name = "Camera Calibration"
  width = 1024
  height = 768

# This enables the obstacle detector
[[observers]]
type = "ObstacleDetector"
# Available methods accepted by ObstacleDetector:
#   - EuclideanClustering
#   - GMM (see below)
method = "EuclideanClustering"

  [ObstacleDetetction.Euclidean.SplitStrategy]
  # Defines the split axxis
  # Values: largest|middle|smallest
  split_axis = "middle"
  # A number of split conditions that need to be satisfied in order for an object
  # split to occur.
  # Care should be taken to define the conditions in a way that guarantees that
  # splitting eventually stops for each object (possibly the easiest way is to
  # always include the DepthLimit condition with a fairly high depth limit).
  # If no split conditions are provided, the objects will never be split.
    [[ObstacleDetetction.Euclidean.SplitStrategy.conditions]]
      type = "DepthLimit"
      depth = 1
    [[ObstacleDetetction.Euclidean.SplitStrategy.conditions]]
      type = "SizeLimit"
      # size is a volume in [cm^3]
      size = 3000.
    [[ObstacleDetetction.Euclidean.SplitStrategy.conditions]]
      type = "ShapeCondition"
      # The threshold values to consider something "very much" a sphere
      sphere1 = 0.8
      sphere2 = 0.1
      # The threshold value to consider something "very much" a cylinder
      cylinder = 0.25
    #[[SplitStrategy.conditions]]
    #  type = "DistanceThreshold"
    #  # Distance is in [cm]
    #  distance_threshold = 150

###########################################################################
# Aggregators is an array
# this will list all aggregators and options belonging to them

# This aggregator sends data to listeners (Path planning, Lab Visualizer, ...) 
[[aggregators]]
type = "RobotAggregator"
# Number of frames to wait before sending new data
update_frequency = 3
# Data to send
data = [ "obstacles", "surfaces", "images", "pointclouds"]
# Human readable target name
target="Vision"
# Target IP
ip = "192.168.0.3"  # QNX computer IP
# Target Port, default is hexadecimal 0xF008
port = 61448
# Delay to wait after sending a message
#delay = 10

###########################################################################
# Miscellaneous settings 

# These settings define basic parameters for detecting the ground plane
# They are mandatory if any kind of surface or obstacle detection is enabled
[BasicSurfaceDetection]
  [BasicSurfaceDetection.RANSAC]
  #max number of ransac iterations
  maxIterations = 200
  # How close a point must be to the model in order to be considered an inlier
  distanceThreshold = 0.03
  #How small the left (extracted) pointcloud should be for termination of the plane segmentation 
  minFilterPercentage = 0.08

  [BasicSurfaceDetection.Classification]
  # The function to classify segmented planes according to deviation in their normals
  # This step is only for Surface Segmentation
  # The angle values represent how much deviation is allowed
  # Given in degrees.
  deviationAngle = 4.0

  [BasicSurfaceDetection.Downsampling]
  #Voxel grid for reducing the number of points before passing them to the clustering step.
  coarseVoxelSize_X = 0.01
  coarseVoxelSize_Y = 0.01
  coarseVoxelSize_Z = 0.01
  fineVoxelSize_X = 0.007
  fineVoxelSize_Y = 0.007
  fineVoxelSize_Z = 0.007
  coarseFineLimit = 11000

  [BasicSurfaceDetection.Clustering]
  #Euclidean clustering to cluster (separate) detected surfaces
  clusterTolerance = 0.05
  minClusterSize = 750

  [BasicSurfaceDetection.SurfaceTracking]
  #How many times an unmaterialized surface should be lost to be completely removed from tracking
  lostLimit = 5
  #How many consecutive times a surface should be detected to be materialized
  foundLimit = 5
  # Allowed deviation for the position of the center point of a surface at the matching for identification
  maxCenterDistance = 0.05
  # Maximum deviation percentage of surface radius such that surfaces can still be mapped to each other
  maxRadiusDeviationPercentage = 0.5

  [BasicSurfaceDetection.ConvexHullApproximation]
  #ConvexHull Method for surface point reduction
  #The number of vertice points of a surface, that is sent to the robot and to the visualizer
  numHullPoints = 8
  # When a new convex hull is merged with an old convex hull, all points of the new convex hull are
  # moved mergeUpdatePercentage percent along the vector pointing to the closest boundary point of
  # the old convex hull. All points of the old convex hull are moved 1-mergeUpdatePercentage percent
  # along the vector pointing to the closest boundary point of the new convex hull.
  mergeUpdatePercentage = 0.2

# These settings define basic parameters for detecting obstacles
# They are mandatory if any kind of bstacle detection is enabled
[BasicObstacleDetection]
  [BasicObstacleDetection.InlierFinder]
  # minimum distance a point must have to its projection onto a 
  # plane in order to be considered an inlier on this plane
  minDistToPlane = 0.04
