# This is a sample of a config file for the vision subsystem (when running
# it with the `--cfg` flag).
# The config file is in the [toml](https://github.com/toml-lang/toml) format,

# All IPs and ports given in here are the defaults for a lab setup.

# Mandatory options are given, optional options are commented out
# and listed with the default values


# Video source
[VideoSource]
# Common options:
#   - `type`: "stream", "oni", "pcd", "am_offline"
# `oni` and `pcd` types require an additional parameter: file_path
# `am_offline` type requires an additional parameters: dir_path
type = "pcd"
file_path = "${AM2B_ROOT}/etc/model/pcd_creation/pcd_single/scene.pcd"
#dir_path = "path/to/folder"
enable_rgb = false  # Capture RGB images
enable_pose = false  # Replay pose data (only am_offline, [PoseService] must be disabled)

# This sets up the filtered source, which will be passed to all
# steps requiring a video
[FilteredVideoSource]
# Pre-filters are applied before pointfilters take effect
# * downsample: reduces the size of the pointcloud by merging neighboring voxels
pre_filter = "downsample"

# Post-filters are applied after the point filters
# options: "prob", "pt1"; These options activate 'source' or 'raw-data' filters.
# For the two options, a voxel grid (or environment map) in world coordinates is created,
# consisting of a big 3D matrix, which is used as a filtered point cloud source
# * prob - each voxel has a probabilistic filter, i.e. is active if it was occupied most times in the last frames
# * pt1 - each voxel has a pt1 filter, i.e. is active if (f*actualframe+(1-f)*previousframe > 0.5)
#post_filter = "prob"

  [FilteredVideoSource.downsample]
  # Size in meters for the "downsample" pre-filter
  cube_size = 0.01

  # The following list of filters is optional
  # The order of the filters themselves IS NOT SIGNIFICANT.
  # each filter requires a "type" and may need additional options


###########################################################################
# Observers is an array
# this will list all observers and options belonging to them


# This defines all available visualizers, there can be more than one
[[observers]]
type = "ARVisualizer"

# Every instance has 4 mandatory options:
# - type: the type of the visualizer
# - name: its name
# - width
# and
# - height: the window dimensions

  # Basic visualizer: shows obstacles (euclidean) and surfaces
  [[observers.visualizer]]
  type = "ObsSurfVisualizer"
  name = "Obs_Surf_Detector"
  width = 1024
  height = 768
  show_obstacles = true
  show_surfaces = true



# This enables the obstacle detector
[[observers]]
type = "ObstacleDetector"

  # Removes points belonging to surfaces from the cloud
  [ObstacleDetection.PlaneRemover]
  # minimum distance a point must have to its projection onto a
  # plane in order to be considered an inlier on this plane
  minDistToPlane = 0.04

  # Segmentation Method
  [ObstacleDetection.Segmenter]
  # Available methods:
  #   - "Euclidean
  #   - "GMM" (see below)
  method = "Euclidean"

  [ObstacleDetection.SplitStrategy]
  # Defines the split axis.
  # The point cloud is splitted with a plane through the centroid and perpendicular to the chosen axis.
  # Values: largest|middle|smallest
  split_axis = "largest"
  # A number of split conditions that need to be satisfied in order for an object
  # split to occur.
  # Care should be taken to define the conditions in a way that guarantees that
  # splitting eventually stops for each object (possibly the easiest way is to
  # always include the DepthLimit condition with a fairly high depth limit).
  # If no split conditions are provided, the objects will never be split.
    [[ObstacleDetection.SplitStrategy.conditions]]
      type = "DepthLimit" # How many 'splitting steps' are performed. Max number of SSV's per obstacle = 2 ^ DepthLimit
     depth = 2
    [[ObstacleDetection.SplitStrategy.conditions]]
      type = "SizeLimit" # After this volume is reached, a sub point cloud is not splitted any more
      # size is a volume in [cm^3]
      size = 3000.
    [[ObstacleDetection.SplitStrategy.conditions]]
      type = "ShapeCondition"
      # The threshold values to consider something "very much" a sphere
      sphere1 = 0.8
      sphere2 = 0.1
      # The threshold value to consider something "very much" a cylinder
      cylinder = 0.25
    #[[SplitStrategy.conditions]]
    #  type = "DistanceThreshold"
    #  # Distance is in [cm]
    #  distance_threshold = 150

[[aggregators]]
type = "ObstacleEvaluator"
ref_volume = 0
#
#
#
#

###########################################################################
# Miscellaneous settings

# These settings define basic parameters for detecting the ground plane
# They are mandatory if any kind of surface or obstacle detection is enabled
[BasicSurfaceDetection]
  [BasicSurfaceDetection.RANSAC]
  #max number of ransac iterations
  maxIterations = 200
  # How close a point must be to the model [in meters] in order to be considered an inlier
  distanceThreshold = 0.03
  #How small the left (extracted) pointcloud should be for termination of the plane segmentation
  minFilterPercentage = 0.08

  [BasicSurfaceDetection.Classification]
  # The function to classify segmented planes according to deviation in their normals
  # This step is only for Surface Segmentation
  # The angle values represent how much deviation is allowed
  # Given in degrees.
  deviationAngle = 4.0

  [BasicSurfaceDetection.Downsampling]
  #Voxel grid for reducing the number of points before passing them to the clustering step.
  coarseVoxelSize_X = 0.01
  coarseVoxelSize_Y = 0.01
  coarseVoxelSize_Z = 0.01
  fineVoxelSize_X = 0.007
  fineVoxelSize_Y = 0.007
  fineVoxelSize_Z = 0.007
  coarseFineLimit = 11000

  [BasicSurfaceDetection.Clustering]
  #Euclidean clustering to cluster (separate) detected surfaces
  clusterTolerance = 0.05 # distance between clusters, in meters
  minClusterSize = 750 # in number of points

  [BasicSurfaceDetection.SurfaceTracking]
  #How many times an unmaterialized surface should be lost to be completely removed from tracking
  lostLimit = 5
  #How many consecutive times a surface should be detected to be materialized
  foundLimit = 5
  # Allowed deviation for the position of the center point of a surface at the matching for identification
  maxCenterDistance = 0.05
  # Maximum deviation percentage of surface radius such that surfaces can still be mapped to each other
  maxRadiusDeviationPercentage = 0.5

  [BasicSurfaceDetection.ConvexHullApproximation]
  #ConvexHull Method for surface point reduction
  #The number of vertice points of a surface, that is sent to the robot and to the visualizer
  numHullPoints = 8
  # When a new convex hull is merged with an old convex hull, all points of the new convex hull are
  # moved mergeUpdatePercentage percent along the vector pointing to the closest boundary point of
  # the old convex hull. All points of the old convex hull are moved 1-mergeUpdatePercentage percent
  # along the vector pointing to the closest boundary point of the new convex hull.
  mergeUpdatePercentage = 0.2

# These settings define basic parameters for detecting obstacles
# They are mandatory if any kind of bstacle detection is enabled
[BasicObstacleDetection]
  [BasicObstacleDetection.InlierFinder]
  # minimum distance a point must have to its projection onto a
  # plane in order to be considered an inlier on this plane
  minDistToPlane = 0.04
