# This is a sample of a config file for the vision subsystem (when running
# it with the `--cfg` flag).
# The config file is in the [toml](https://github.com/toml-lang/toml) format,

[PoseService]
ip = "192.168.0.8"
# (The hex port value is equal to the decimal below) port = 0xd001
port = 53249


[Robot]
# The size of the "bubble" in which no modifications or deletions of objects
# are sent to the robot. **In meters**
bubble_size = 1.2

[VideoSource]
# Common options:
#   - `type`: stream, oni, pcd, am_offline
# `oni` and `pcd` types require an additional parameter: file_path
# `am_offline` type requires an additional parameters: dir_path
type = "stream"
enable_rgb = true

[FilteredVideoSource]
# type = simple|prob|pt1
type = "simple"

  # The following list of filters is optional
  # The order of the filters themselves IS NOT SIGNIFICANT.
  [[FilteredVideoSource.filters]]
    type = "SensorCalibrationFilter"
    a = 1.0117
    b = -0.0100851

  [[FilteredVideoSource.filters]]
    # The OdoTransformer knows to reference the PoseService found in the IOC
    # container automatically
    type = "RobotOdoTransformer"

  [[FilteredVideoSource.filters]]
    type = "TruncateFilter"
    decimal_points = 2

# Available `observer` types: ObstacleDetector|SurfaceDetector|Recorder
#   ObstacleDetector requires *SplitStrategy*
#   ObstacleDetector implies having a SurfaceDetector as well, so do not
#     specify an ObstacleDetector and a SurfaceDetector at the same time.
#   Recorder requires RecordingOptions
[[observers]]
type = "ObstacleDetector"
method = "EuclideanClustering"

[[observers]]
type = "SurfaceDetector"





[[aggregators]]
type = "RobotAggregator"
update_frequency = 3
#data = [ "obstacles", "surfaces", "pointclouds", "images" ]
data = [ "pointclouds" ]
  [[aggregators.RobotService]]
  target="Vision"
  ip = "192.168.0.3"  # control computer IP
  port = 61448
  delay = 0

[SplitStrategy]
# split_axis = largest|middle|smallest
split_axis = "middle"
# A number of split conditions that need to be satisfied in order for an object
# split to occur.
# Care should be taken to define the conditions in a way that guarantees that
# splitting eventually stops for each object (possibly the easiest way is to
# always include the DepthLimit condition with a fairly high depth limit).
# If no split conditions are provided, the objects will never be split.
  [[SplitStrategy.conditions]]
    type = "DepthLimit"
    depth = 1
#  [[SplitStrategy.conditions]]
#    type = "SizeLimit"
#    # size is a volume in [cm^3]
#    size = 3000.
#  [[SplitStrategy.conditions]]
#    type = "ShapeCondition"
#    # The threshold values to consider something "very much" a sphere
#    sphere1 = 0.8
#    sphere2 = 0.1
#    # The threshold value to consider something "very much" a cylinder
#    cylinder = 0.25
#  #[[SplitStrategy.conditions]]
#  #  type = "DistanceThreshold"
#  #  # Distance is in [cm]
#  #  distance_threshold = 150


#Parameters for Surface Segmentation
#SurfaceFinder.hpp
[RANSAC]
#max number of ransac iterations
maxIterations = 200
# How close a point must be to the model in order to be considered an inlier
distanceThreshold = 0.03
#How small the left (extracted) pointcloud should be for termination of the plane segmentation 
minFilterPercentage = 0.08

[Classification]
#The function to classify segmented planes according to deviation in their normals
#This step is only for Surface Segmentation
#The angle values represent how much deviation is allowed
#Given in degrees.
deviationAngle = 4.0

[Downsampling]
#Voxel grid for reducing the number of points before passing them to the clustering step.
coarseVoxelSize_X = 0.01
coarseVoxelSize_Y = 0.01
coarseVoxelSize_Z = 0.01
fineVoxelSize_X = 0.007
fineVoxelSize_Y = 0.007
fineVoxelSize_Z = 0.007
coarseFineLimit = 11000

[Clustering]
#Euclidean clustering to cluster (separate) detected surfaces
clusterTolerance = 0.05
minClusterSize = 750

[SurfaceTracking]
#How many times an unmaterialized surface should be lost to be completely removed from tracking 
lostLimit = 5
#How many consecutive times a surface should be detected to be materialized
foundLimit = 5
# Allowed deviation for the position of the center point of a surface at the matching for identification
maxCenterDistance = 0.05
# Maximum deviation percentage of surface radius such that surfaces can still be mapped to each other
maxRadiusDeviationPercentage = 0.5

[ConvexHullApproximation]
#ConvexHull Method for surface point reduction
#The number of vertice points of a surface, that is sent to the robot and to the visualizer
numHullPoints = 8
# When a new convex hull is merged with an old convex hull, all points of the new convex hull are
# moved mergeUpdatePercentage percent along the vector pointing to the closest boundary point of 
# the old convex hull. All points of the old convex hull are moved 1-mergeUpdatePercentage percent 
# along the vector pointing to the closest boundary point of the new convex hull.
mergeUpdatePercentage = 0.2

[InlierFinder]
# minimum distance a point must have to its projection onto a 
# plane in order to be considered an inlier on this plane
minDistToPlane = 0.04

[[observers]]
type = "ARVisualizer"

  [[observers.visualizer]]
  type = "ObsSurfVisualizer"
  name = "Obs_Surf_Detector"
  width = 1024
  height = 768
  show_obstacles = true
  show_surfaces = true

